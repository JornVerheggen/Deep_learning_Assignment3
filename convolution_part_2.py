# -*- coding: utf-8 -*-
"""Convolution_part_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UfmCdGuqU8pMmwSAkaYv0I5SHfRZhwEE
"""

import numpy as np
import torchvision
import torch
import torchvision.transforms
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib as plt
from torch.autograd import Variable
import matplotlib.pyplot as plt

if __name__ == '__main__':

    print('hello')
    batch_size = 16

    train = torchvision.datasets.MNIST(
        root='./data', train=True, download=True, transform=transforms.ToTensor())
    train, validation = torch.utils.data.random_split(train, [50000, 10000])

    trainloader = torch.utils.data.DataLoader(
        train, batch_size=batch_size, shuffle=True, num_workers=2)
    validationloader = torch.utils.data.DataLoader(
        validation, batch_size=batch_size, shuffle=True, num_workers=2)

    test = torchvision.datasets.MNIST(
        root='./data', train=False, download=True, transform=transforms.ToTensor())
    testloader = torch.utils.data.DataLoader(
        test, batch_size=batch_size, shuffle=True, num_workers=2)

    class Net(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
            self.pool = nn.MaxPool2d(2)
            self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
            self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
            self.fc1 = nn.Linear(64*3*3, 10)

        def forward(self, x):
            batch = 16
            assert x.shape == (
                batch, 1, 28, 28), f'expected {(batch, 1, 28, 28)} but got: {x.shape}'
            x = self.pool(F.relu(self.conv1(x)))
            assert x.shape == (
                batch, 16, 14, 14), f'OUR Assert expected {(batch, 16, 14, 14)} but got: {x.shape}'
            x = self.pool(F.relu(self.conv2(x)))

            assert x.shape == (
                batch, 32, 7, 7), f'OUR Assert expected {(batch, 32, 7, 7)} but got: {x.shape}'
            x = self.pool(F.relu(self.conv3(x)))

            assert x.shape == (
                batch, 64, 3, 3), f'OUR Assert expected {(batch, 64, 3, 3)} but got: {x.shape}'

            x = torch.reshape(x, (batch, 64 * 3 * 3))
            x = self.fc1(x)

            return x

    cnn = Net()
    loss_func = nn.CrossEntropyLoss()
    optimizer = optim.Adam(cnn.parameters(), lr=0.0005)

    num_epochs = 5

    def Validate(model, loss_func, dataloader):
        lossTotal = 0.0
        accuracyTotal = 0.0
        with torch.no_grad():
            for data, labels in dataloader:
                target = model(data)
                # calc loss
                loss = loss_func(target, labels)
                lossTotal = loss.item() * data.size(0)

                # calc accuracy
                _, predicted = torch.max(target.data, 1)
                accuracyTotal += (predicted == labels).sum().item() / \
                    predicted.size(0)

        accuracy = accuracyTotal / len(dataloader)
        finalLoss = lossTotal / len(dataloader)
        return accuracy, finalLoss

    def train(num_epochs, cnn, optimizer):
        data = dict(train=[], validate=[])
        cnn.train()

        # Train the model
        total_step = len(trainloader)

        for epoch in range(num_epochs):
            for i, (images, labels) in enumerate(trainloader):

                optimizer.zero_grad()

                # gives batch data, normalize x when iterate train_loader
                b_x = Variable(images)   # batch x
                b_y = Variable(labels)   # batch y
                output = cnn(b_x)
                loss = loss_func(output, b_y)

                # clear gradients for this training step
                optimizer.zero_grad()

                # backpropagation, compute gradients
                loss.backward()
                # apply gradients
                optimizer.step()

                if (i+1) % 100 == 0:
                    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(
                        epoch + 1, num_epochs, i + 1, total_step, loss.item()))

            # at each epoch: validate progress with both datasets
            val_accuracy, val_loss = Validate(cnn, loss_func, validationloader)
            print(
                f"Epoch:{epoch}, Validation accuracy:{val_accuracy}, Validation loss: {val_loss}")
            data["validate"].append([epoch, val_accuracy, val_loss])

            train_accuracy, train_loss = Validate(cnn, loss_func, trainloader)
            print(
                f"Epoch:{epoch}, Train accuracy:{train_accuracy}, Train loss: {train_loss}")
            data["train"].append([epoch, train_accuracy, train_loss])
        return data

    result = train(num_epochs, cnn, optimizer)
    with open('Q7_results.txt', 'w') as f:
        print(result, file=f)

    def test2():
        cnn.eval()
        test_loss = []
        test_accuracy = []
        with torch.no_grad():
            for i, (data, labels) in enumerate(testloader):
                # pass data through network
                outputs = cnn(data)
                _, predicted = torch.max(outputs.data, 1)
                loss = loss_func(outputs, labels)
                test_loss.append(loss.item())
                test_accuracy.append(
                    (predicted == labels).sum().item() / predicted.size(0))
            print('test loss: {}, test accuracy: {}'.format(
                np.mean(test_loss), np.mean(test_accuracy)))
        return np.mean(test_accuracy)

    accuracy = test2()

    print(
        f'Test Accuracy of the model on the 10000 test images: {100 * accuracy:.2f}%')

    epochs = [x[0]+1 for x in result["train"]]
    plt.plot(epochs, [x[1]
             for x in result["train"]], marker='o', label='train')
    plt.plot(epochs, [x[1] for x in result["validate"]],
             marker='*', label='validate')
    plt.title(f"Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.savefig("Q7_Accuracy.pdf")
    plt.show()

    plt.plot(epochs, [x[2]
             for x in result["train"]], marker='o', label='train')
    plt.plot(epochs, [x[2] for x in result["validate"]],
             marker='*', label='validate')
    plt.title(f"Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.savefig("Q7_Loss.pdf")
    plt.show()
